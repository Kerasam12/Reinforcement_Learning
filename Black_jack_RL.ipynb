{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c80501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "043b72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Blackjack-v1\", natural = True , sab = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1000675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f312ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 1, 0), 0.0, False, False, {})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4865733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14, 1, 0), -1.0, True, False, {})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4135317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION SPACE:\n",
      " Discrete(2) : HIT or STICK\n",
      "\n",
      "OBSERVATION SPACE:\n",
      " Tuple(Discrete(32), Discrete(11), Discrete(2)) : user_sum, dealer_card, if_usable_ace_of_user\n"
     ]
    }
   ],
   "source": [
    "print(\"ACTION SPACE:\\n\",env.action_space, \": HIT or STICK\\n\")\n",
    "print(\"OBSERVATION SPACE:\\n\",env.observation_space, \": user_sum, dealer_card, if_usable_ace_of_user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff65ece",
   "metadata": {},
   "source": [
    "## 2.1 Naı̈ve Policy\n",
    "Implement an agent that carries out the following deterministic policy:\n",
    "\n",
    "• The agent will stick if it gets a score of 20 or 21.\n",
    "\n",
    "• Otherwise, it will hit.\n",
    "\n",
    "Questions:\n",
    "1. Using this agent, simulate 100,000 games and calculate the agent’s return\n",
    "(total accumulated reward).\n",
    "2. Additionally, calculate the % of wins, natural wins, losses and draws.\n",
    "3. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0413335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveAgent():\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        \n",
    "        \n",
    "    def apply_policy(self,state):\n",
    "        \n",
    "        if state[0] >= 20:\n",
    "            action = 0\n",
    "        else:\n",
    "            action = 1\n",
    "            \n",
    "        return action\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e738ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward: -54192.0\n",
      "num_wins: 20.924 %\n",
      "num_natural_wins: 0.0 %\n",
      "num loses: 75.116 %\n",
      "num_draws: 3.9600000000000004 %\n",
      "total_played: 100000\n"
     ]
    }
   ],
   "source": [
    "num_plays = 100000\n",
    "naive_agent = NaiveAgent(env)\n",
    "total_reward = 0 \n",
    "wins = 0\n",
    "natural_wins = 0\n",
    "draws = 0 \n",
    "loses = 0\n",
    "\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "for ply in range(num_plays):\n",
    "    \n",
    "    env.reset()\n",
    "    action = 1 \n",
    "    \n",
    "    while not terminated or truncated:\n",
    "        new_state, reward, terminated, truncated,_ = env.step(action)\n",
    "        \n",
    "        total_reward += reward\n",
    "        action = naive_agent.apply_policy(new_state)\n",
    "        \n",
    "        if reward == 1:\n",
    "            wins += 1\n",
    "        elif reward == 1.5:\n",
    "            natural_wins += 1\n",
    "        elif reward == -1:\n",
    "            loses += 1\n",
    "        elif reward == 0 and (terminated or truncated):\n",
    "            draws += 1 \n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "print(\"total_reward:\", total_reward)\n",
    "print(\"num_wins:\", (wins/num_plays)*100,\"%\")\n",
    "print(\"num_natural_wins:\",(natural_wins/num_plays)*100,\"%\")\n",
    "print(\"num loses:\", (loses/num_plays)*100,\"%\")\n",
    "print(\"num_draws:\", (draws/num_plays)*100,\"%\")\n",
    "print(\"total_played:\", wins+loses+natural_wins + draws)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecb560",
   "metadata": {},
   "source": [
    "### Comment of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef059f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79774ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc43a118",
   "metadata": {},
   "source": [
    "## 2.2 Monte Carlo method\n",
    "The objective of this section is to estimate the optimal policy using Monte Carlo\n",
    "methods, specifically we will study algorithm “Control using MC methods with\n",
    "initial explorations”.\n",
    "Questions:\n",
    "\n",
    "1. Implement Algorithm 1 using the following parameters:\n",
    "\n",
    "• Number of episodes = 5,000,000\n",
    "\n",
    "• Discount factor = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe09adf",
   "metadata": {},
   "source": [
    "2. Implement a function that prints on the screen the optimal policy found for\n",
    "each state (similar to figure 2).\n",
    "3. Using the agent obtained through the Monte Carlo method, simulate 100,000\n",
    "games and calculate the agent’s return (total accumulated reward).\n",
    "4. Additionally, calculate the % of wins, natural wins, losses and draws.\n",
    "5. Compare the optimal policy found by our agent to the optimal policy (see\n",
    "figure 2).\n",
    "6. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dd766c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "cbc50182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MC_Agent():\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.Returns = collections.defaultdict(list)\n",
    "        self.possible_user_sum = self.env.observation_space[0].n\n",
    "        self.possible_dealer_sum = self.env.observation_space[1].n\n",
    "        self.usable_ace = self.env.observation_space[2].n\n",
    "        self.possible_actions = self.env.action_space.n\n",
    "        self.Q = np.zeros((self.possible_user_sum, self.possible_dealer_sum, self.usable_ace, self.possible_actions))\n",
    "        self.policy = np.ones((self.possible_user_sum, self.possible_dealer_sum, self.usable_ace, self.possible_actions))/2\n",
    "        \n",
    "    \n",
    "    def update_Returns(self,state, action,G):\n",
    "        \n",
    "        self.Returns[(state,action)].append(G)\n",
    "        \n",
    "    def update_Q(self,state, action):\n",
    "        self.Q[state[0],state[1],state[2], action] = np.mean(self.Returns[(state,action)])\n",
    "        \n",
    "    def epsilon_greedy_policy(self,state,epsilon):\n",
    "        '''total_probs = np.ones((self.possible_user_sum, self.possible_dealer_sum, self.usable_ace, self.possible_actions))/2\n",
    "        for pu in range(self.possible_user_sum):\n",
    "            for pd in range(self.possible_dealer_sum):\n",
    "                for a in range(self.usable_ace):'''\n",
    "        probs = (np.ones(self.possible_actions) * epsilon) / self.possible_actions\n",
    "        best_action = np.argmax(self.Q[state[0]][state[1]][state[2]])\n",
    "        probs[best_action] += 1.0 - epsilon\n",
    "        #total_probs[pu][pd][a] = probs\n",
    "        self.policy[state[0],state[1],state[2]] = probs\n",
    "                    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d7b78e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(env,agent):\n",
    "    obs,_ = env.reset()\n",
    "    action =  np.random.choice(range(len(agent.policy[obs[0],obs[1],obs[2]])), p = agent.policy[obs[0],obs[1],obs[2]])\n",
    "    EPS = []\n",
    "    total_reward = 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    while not terminated or truncated:\n",
    "        \n",
    "        new_state, reward, terminated, truncated,_ = env.step(action)\n",
    "        \n",
    "        EPS.append((obs,action,reward))\n",
    "        total_reward += reward\n",
    "        #print(agent.policy[new_state[0],new_state[1],new_state[2]])\n",
    "        action = np.random.choice(range(len(agent.policy[new_state[0],new_state[1],new_state[2]])), p = agent.policy[new_state[0],new_state[1],new_state[2]])\n",
    "        obs = new_state\n",
    "    return EPS\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "31833456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 10, 0), {})"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c4a69836",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 5000000\n",
    "discount_factor = 1 \n",
    "epsilon = 0.1\n",
    "epsilon_decay = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2028f",
   "metadata": {},
   "source": [
    "Define the general loop for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "fd54e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[311], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m         seen_states\u001b[38;5;241m.\u001b[39mappend((eps[\u001b[38;5;241m0\u001b[39m], eps[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     11\u001b[0m         mc_agent\u001b[38;5;241m.\u001b[39mupdate_Returns(eps[\u001b[38;5;241m0\u001b[39m],eps[\u001b[38;5;241m1\u001b[39m],G)\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mmc_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_Q\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43meps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         mc_agent\u001b[38;5;241m.\u001b[39mepsilon_greedy_policy(eps[\u001b[38;5;241m0\u001b[39m],epsilon)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[300], line 18\u001b[0m, in \u001b[0;36mMC_Agent.update_Q\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_Q\u001b[39m(\u001b[38;5;28mself\u001b[39m,state, action):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ[state[\u001b[38;5;241m0\u001b[39m],state[\u001b[38;5;241m1\u001b[39m],state[\u001b[38;5;241m2\u001b[39m], action] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReturns\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3433\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/_methods.py:164\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 164\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc_agent = MC_Agent(env)\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    EPS = generate_episode(env,mc_agent)\n",
    "    G = 0 \n",
    "    seen_states = []\n",
    "    for eps in reversed(EPS):\n",
    "        G = (discount_factor*G) + eps[2]\n",
    "        if (eps[0], eps[1]) not in seen_states:\n",
    "            seen_states.append((eps[0], eps[1]))\n",
    "            mc_agent.update_Returns(eps[0],eps[1],G)\n",
    "            mc_agent.update_Q(eps[0],eps[1])\n",
    "            mc_agent.epsilon_greedy_policy(eps[0],epsilon)\n",
    "    if i% 1000 == 0:\n",
    "        epsilon = epsilon *epsilon_decay \n",
    "    if i% 100000 == 0:\n",
    "        print(i)\n",
    "        #print(mc_agent.policy)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_use_ace= np.zeros((pol.shape[0],pol.shape[1]))\n",
    "not_use_ace_deal = np.zeros((pol.shape[0],pol.shape[1]))\n",
    "\n",
    "usable_ace= np.zeros((pol.shape[0],pol.shape[1]))\n",
    "usable_ace_deal = []\n",
    "pol = mc_agent.policy\n",
    "for usr_sum in range(pol.shape[0]):\n",
    "    for deal_sum in range(pol.shape[1]):\n",
    "        for a in range(pol.shape[2]):\n",
    "            if a == 0:\n",
    "                #print(np.argmax(pol[usr_sum,deal_sum,a]))\n",
    "                not_use_ace[usr_sum][deal_sum] = np.argmax(pol[usr_sum,deal_sum,a])\n",
    "                #not_use_ace.append(np.max(pol[usr_sum,deal_sum,a]))\n",
    "            elif a == 1:\n",
    "                usable_ace[usr_sum][deal_sum] = np.argmax(pol[usr_sum,deal_sum,a])\n",
    "                #usable_ace.append(np.max(pol[usr_sum,deal_sum,a]))\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c8d2c65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usable_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "81b2dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_use_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6ad2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from numpy import meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "38fe1377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "       [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_use_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "54df1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(np.max(mc_agent.policy).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "863a7898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]],\n",
       "\n",
       "\n",
       "       [[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]],\n",
       "\n",
       "\n",
       "       [[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]],\n",
       "\n",
       "\n",
       "       [[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]],\n",
       "\n",
       "\n",
       "       [[[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]],\n",
       "\n",
       "        [[0.9, 0.1],\n",
       "         [0.9, 0.1]]]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_agent.policy[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "4b5a619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7fd5d36caad0>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z = not_use_ace\n",
    "x = np.arange(pol.shape[0])  # \n",
    "print(x)\n",
    "y = np.arange(pol.shape[1])  # \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolormesh(y, x, Z, vmin=np.min(Z), vmax=np.max(Z), shading = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e0cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51203365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d4420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def plot_policy(policy):\n",
    "\n",
    "    def get_Z(player_hand, dealer_showing, usable_ace):\n",
    "        if (player_hand, dealer_showing, usable_ace) in policy:\n",
    "            return policy[player_hand, dealer_showing, usable_ace]\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_figure(usable_ace, ax):\n",
    "        x_range = np.arange(1, 11)\n",
    "        y_range = np.arange(11, 22)\n",
    "        X, Y = np.meshgrid(x_range, y_range)\n",
    "        Z = np.array([[get_Z(player_hand, dealer_showing, usable_ace) for dealer_showing in x_range] for player_hand in range(21, 10, -1)])\n",
    "        surf = ax.imshow(Z, cmap=plt.get_cmap('Accent', 2), vmin=0, vmax=1, extent=[0.5, 10.5, 10.5, 21.5])\n",
    "        plt.xticks(x_range, ('A', '2', '3', '4', '5', '6', '7', '8', '9', '10'))\n",
    "        plt.yticks(y_range)\n",
    "        ax.set_xlabel('Dealer Showing')\n",
    "        ax.set_ylabel('Player Hand')\n",
    "        ax.grid(color='black', linestyle='-', linewidth=1)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "        cbar = plt.colorbar(surf, ticks=[0, 1], cax=cax)\n",
    "        cbar.ax.set_yticklabels(['0 (STICK)','1 (HIT)'])\n",
    "        cbar.ax.invert_yaxis() \n",
    "            \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.set_title('Usable Ace', fontsize=16)\n",
    "    get_figure(True, ax)\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.set_title('No Usable Ace', fontsize=16)\n",
    "    get_figure(False, ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8764b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_policy(mc_agent.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a69923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635f16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d114db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
